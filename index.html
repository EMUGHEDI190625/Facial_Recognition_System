<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ECN Face Recognition System</title>

  <!-- Load face-api.js -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 10px;
      background: #f4f4f4;
    }
    video, canvas {
      border: 2px solid #000;
      border-radius: 8px;
      margin-top: 10px;
    }
    input, button {
      margin: 5px;
      padding: 8px;
      font-size: 16px;
    }
    #faceStatus {
      margin-top: 10px;
      font-weight: bold;
      color: green; /* always green */
    }
    #sheetStatus {
      margin-top: 5px;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h2>ECN Face Recognition System</h2>

  <input type="text" id="employeeId" placeholder="Enter Employee ID" required><br>
  <button id="startBtn" disabled>Start Camera</button>

  <p id="faceStatus">Loading models...</p>
  <p id="sheetStatus"></p>

  <video id="video" width="320" height="240" autoplay muted></video>
  <canvas id="overlay" width="320" height="240"></canvas>

  <script>
    const faceStatusEl = document.getElementById("faceStatus");
    const sheetStatusEl = document.getElementById("sheetStatus");
    const startBtn = document.getElementById("startBtn");
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");

    let labeledDescriptors = [];
    let faceMatcher;

    let lastRecognized = null;
    let recognizedToday = {}; // { employeeId: { YYYY-MM-DD: true } }

    const SHEET_URL = "https://script.google.com/macros/s/AKfycbwgR4WR6bgDBj_xbaCeOorVfHWp5fKwuB8lN3fR4Fy2ckHTJ9pBBC2tdyXVImNtGcqT6Q/exec";

    async function loadModels() {
      faceStatusEl.textContent = "â³ Loading models...";
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models/'),
          faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models/'),
          faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models/')
        ]);
        faceStatusEl.textContent = "âœ… Models loaded. Enter Employee ID and start camera.";
        startBtn.disabled = false;
      } catch(err) {
        faceStatusEl.textContent = "âŒ Error loading models: " + err;
        console.error(err);
      }
    }

    async function loadAuthorizedFaces() {
      labeledDescriptors = [];
      const authorizedNames = ["John Doe", "Jane Smith", "Ikata Kenoye"];
      for (const name of authorizedNames) {
        try {
          const img = await faceapi.fetchImage(`./images/${name}.jpg`);
          const detection = await faceapi
            .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptor();
          if (detection) {
            labeledDescriptors.push(
              new faceapi.LabeledFaceDescriptors(name, [detection.descriptor])
            );
            console.log(`âœ… Loaded authorized face for ${name}`);
          } else console.warn(`âš ï¸ No face detected in ${name}.jpg`);
        } catch (err) {
          console.error(err);
        }
      }
      faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
    }

    async function sendAttendanceToScript(employeeId, status, imageDataURL){

      const url = "YOUR_NEW_WEBAPP_URL";
      
      const formData = new FormData();
      formData.append("employeeId", employeeId);
      formData.append("status", status);
      formData.append("image", imageDataURL);
      
      try{
        const res = await fetch(url,{
          method:"POST",
          body:formData
        });
      
        const text = await res.text();
        console.log(text);
      
        sheetStatusEl.style.color="green";
        sheetStatusEl.textContent="âœ… Attendance sent";
      
      }catch(err){
        sheetStatusEl.style.color="red";
        sheetStatusEl.textContent="âŒ Network Error: "+err.message;
      }
      }

    startBtn.onclick = async () => {
      const employeeId = document.getElementById("employeeId").value.trim();
      if (!employeeId) return alert("Please enter Employee ID.");

      await loadAuthorizedFaces();

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        await video.play();
        faceStatusEl.style.color = "green";
        faceStatusEl.textContent = "ðŸŽ¥ Camera started â€” detecting faces...";

        setInterval(async () => {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();

          ctx.clearRect(0, 0, canvas.width, canvas.height);
          faceapi.matchDimensions(canvas, { width: video.width, height: video.height });
          const resized = faceapi.resizeResults(detections, { width: video.width, height: video.height });

          const results = resized.map(d => faceMatcher.findBestMatch(d.descriptor));
          const today = new Date().toISOString().split("T")[0];

          for (let i = 0; i < results.length; i++) {
            const result = results[i];
            const box = resized[i].detection.box;
            const statusText = result.label === "unknown" ? "Unauthorized" : `Authorized: ${result.label}`;
            const timeNow = new Date().toLocaleTimeString();

            // Draw label + timestamp on video
            const drawBox = new faceapi.draw.DrawBox(box, { label: `${statusText} | ${timeNow}` });
            drawBox.draw(canvas);

            // Always show face detected info in green
            faceStatusEl.textContent = `Face detected: ${statusText} | ${timeNow}`;

            if (!recognizedToday[employeeId]) recognizedToday[employeeId] = {};
            if (!recognizedToday[employeeId][today]) {
              recognizedToday[employeeId][today] = true;

              const captureCanvas = document.createElement("canvas");
              captureCanvas.width = video.videoWidth;
              captureCanvas.height = video.videoHeight;
              captureCanvas.getContext("2d").drawImage(video, 0, 0, captureCanvas.width, captureCanvas.height);
              const imageDataURL = captureCanvas.toDataURL("image/jpeg");

              await sendAttendanceToScript(employeeId, statusText, imageDataURL);

            }
          }
        }, 1500);
      } catch(err) {
        faceStatusEl.style.color = "red";
        faceStatusEl.textContent = "âš ï¸ Camera error: " + err.message;
        console.error(err);
      }
    };

    window.addEventListener("load", loadModels);
  </script>
</body>
</html>








